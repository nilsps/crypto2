---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r, install packages}
library(crypto2)
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(lubridate)){install.packages("lubridate")}
if(!require(glmnet)){install.packages("glmnet")}
library(tidyverse)                      # Activate the data science package
library(lubridate)                      # Activate the date management package
library(glmnet)                         # Package for penalized regressions
library(cowplot)
if(!require(glmnet)){install.packages("glmnet")}
library(glmnet)                                     # This is THE package for penalised regressions
library(tidyverse)                                  # ... the usual core packages
```

```{r, loading coin data}
coins_overview = crypto_list()
#coin_history = crypto_history(coins_overview, limit=NROW(coins_overview), start_date="20200101")
coin_history = crypto_history(coins_overview, limit=20, start_date="20150101")

saveRDS(coins_overview, file = "short_coin_overview.RData")
saveRDS(coin_history, file = "short_coin_history_30032021.RData")
```

```{r first, warning = FALSE, message = FALSE}
data <- coin_history %>% arrange(time_open,name)                 # Just making sure all is in order
id = levels(data$name)                           # Set of assets
data <- data  %>% 
    group_by(name) %>%                              # Group asset by asset
    mutate(P_Return = close / lag(close) - 1) %>%   # Adding past returns
    mutate(F_Return = dplyr::lead(P_Return)) %>%           # Adding forward returns
    na.omit()                                     # Take out missing data
    
data$time_open = as.Date(as.POSIXct(data$time_open))
    
```

```{r reg, warning = FALSE, message = FALSE}
data %>% group_by(time_open) %>%             # Grouping to normalise on a date basis
    mutate_if(is.numeric,scale) %>%     # Scaled chars
    ungroup() %>%                       # Ungroup: global variable
    select(-timestamp, -slug, -id, -name, -symbol, -ref_cur, -time_open, -time_high, -time_low, -time_close) %>%    # Take out irrelevant columns for the regression
    lm(F_Return ~ ., data = .) %>%      # Perform the regression
    summary() %>%                       # Get the summary
    "$"(coef) %>%                       # Keeping only the coefs & stats
    round(3) %>%                        # Round up to 3 digits
    data.frame()                        # Convert to dataframe
```


```{r lasso_1, warning = FALSE, message = FALSE}
data_lasso <-  data %>% group_by(time_open) %>%          # Grouping to normalise on a date-by-date basis
    mutate_if(is.numeric,scale) %>%                 # Scaled chars
    ungroup()  #%>%                                  # Ungroup: global variable
  #filter(Tick=="AAPL")
y <- data_lasso$F_Return                            # Dependent variable
x <- data_lasso %>%                                 # Independent variables
    select(-timestamp, -slug, -id, -name, -symbol, -ref_cur, -time_open, -time_high, -time_low, -time_close) %>%    # Removing irrelevant columns
    as.matrix()                                     # Transform in base matrix
fit <- glmnet(x,y, alpha = 0.005)                       # Performing the LASSO: 1 = Lasso, 0 = Ridge
# Below, we format the results
var_names1 =  colnames(data)[7:12]                # Names of independent variables
var_names2 =  colnames(data)[17:18] 
var_names = c(var_names1, var_names2)
res <- summary(fit$beta)                            # Summary of the series of LASSO regressions
lambda <- fit$lambda                                # Values of the penalisation constant
res$Lambda <- lambda[res$j]                         # Putting the labels where they belong
res$Char <- var_names[res$i] %>% as.factor()        # Adding names of variables to the output
res %>% ggplot(aes(x = Lambda, y = x, color = Char)) + geom_line() # Plot!
```
```{r, ridge}
fit <- glmnet(x,y, alpha = 0)                   # Performing ridge regression: 1 = Lasso, 0 = Ridge
res <- summary(fit$beta)                        # Summary of the series of ridge regressions
lambda <- fit$lambda                            # Values of the penalisation constant
res$Lambda <- lambda[res$j]                     # Putting the labels where they belong
res$Char <- var_names[res$i] %>% as.factor()    # Adding the names of variables to the output
res %>% ggplot(aes(x = Lambda, y = x, color = Char)) + geom_line() # Plot!
res %>% ggplot(aes(x = Lambda, y = x, color = Char)) + geom_line() + scale_x_log10() # Logscale plot
```

```{r, elasticnet}
fit <- glmnet(x,y, alpha = 0.01)                   # The elasticnet: 1 = Lasso, 0 = Ridge
res <- summary(fit$beta)                            # Summary of elasticnet regressions
lambda <- fit$lambda                                # Values of the penalisation constant
res$Lambda <- lambda[res$j]                         # Putting the labels where they belong
res$Char <- var_names[res$i] %>% as.factor()        # Adding the names of variables to the output
res %>% ggplot(aes(x = Lambda, y = x, color = Char)) + geom_line()
```
### WIP

```{r sparse_init, warning = FALSE, message = FALSE}
sep_date <- as.Date("2017-01-01")           # This date separates in-sample vs out-of-sample
t_oos <- data$time_open[data$time_open>sep_date] %>%  # Out-of-sample dates (i.e., testing set)
    unique() %>%                            # Remove duplicates
    as.Date(origin = "1970-01-01")          # Transform in date format
returns <- data %>%                         # Computing returns, in matrix format, in 2 steps:
    select(time_open, name, P_Return) %>%        # 1. Keep returns along with dates & firm names
    spread(key = name, value = P_Return)    # 2. Put in matrix shape
# Below, we initialise the variables used in the backtesting loop
portf_weights <- tibble(0, nrow = length(t_oos), ncol = length(id))
portf_returns <- c()                                                  
returns                                     # A look at the returns
```

```{r sparse_func}
weights_lasso <- function(returns, alpha, lambda){  # The parameters are defined here
    w <- 0                                          # Initiate weights
    for(i in 1:ncol(returns)){                      # Loop on the assets
        y <- returns[,i]                            # Dependent variable
        x <- returns[,-i]                           # Independent variable
        fit <- glmnet(x,y, family = "gaussian", alpha = alpha, lambda = lambda)
        err <- y-predict(fit, x)                    # Prediction errors
        w[i] <- (1-sum(fit$beta))/var(err)          # Output: weight of asset i
    }
    return(w / sum(w))                              # Normalisation of weights
}
```

###
# Problem, some values are NA, what if we replace NA with mean of closes neighboors? 
# 
```{r sparse_go}
for(t in 1:length(t_oos)){
    temp_data <- returns %>% filter(time_open < t_oos[t]) %>%    # Extracting past data: expand. window 
        select(-time_open) %>%                                   # Take out the date
        as.matrix()                                         # Into matrix: glmnet requires matrices
    portf_weights[t,] <- weights_lasso(temp_data, 0.1, 0.01)# Hard-coded parameters! User specified!
    realised_returns <- returns %>%                         # Realised returns:
        filter(Date ==  t_oos[t]) %>%                       # Filtered by date
        select(-Date)                                       # With date removed
    portf_returns[t] <- sum(portf_weights[t,] * realised_returns) # Portfolio returns
}
```





